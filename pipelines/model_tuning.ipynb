{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c74ce473-a981-4a83-90c3-40064cfdd6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset Split Complete:\n",
      "   - Training Set: 674 (To teach Gemma)\n",
      "   - Test Set: 191 (The Final Exam)\n",
      "   - Pre-Eval Set: 97 (The Baseline)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:9: SyntaxWarning: \"\\S\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\S\"? A raw string is also an option.\n",
      "<>:11: SyntaxWarning: \"\\S\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\S\"? A raw string is also an option.\n",
      "<>:12: SyntaxWarning: \"\\S\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\S\"? A raw string is also an option.\n",
      "<>:13: SyntaxWarning: \"\\]\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\]\"? A raw string is also an option.\n",
      "<>:15: SyntaxWarning: \"\\s\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\s\"? A raw string is also an option.\n",
      "<>:9: SyntaxWarning: \"\\S\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\S\"? A raw string is also an option.\n",
      "<>:11: SyntaxWarning: \"\\S\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\S\"? A raw string is also an option.\n",
      "<>:12: SyntaxWarning: \"\\S\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\S\"? A raw string is also an option.\n",
      "<>:13: SyntaxWarning: \"\\]\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\]\"? A raw string is also an option.\n",
      "<>:15: SyntaxWarning: \"\\s\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\s\"? A raw string is also an option.\n",
      "/var/folders/2l/wp6j5fjs0j39hw2d7mwtt6t80000gn/T/ipykernel_65767/2971115876.py:9: SyntaxWarning: \"\\S\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\S\"? A raw string is also an option.\n",
      "  text = re.sub('http\\S+\\s*', ' ', text)\n",
      "/var/folders/2l/wp6j5fjs0j39hw2d7mwtt6t80000gn/T/ipykernel_65767/2971115876.py:11: SyntaxWarning: \"\\S\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\S\"? A raw string is also an option.\n",
      "  text = re.sub('#\\S+', '', text)\n",
      "/var/folders/2l/wp6j5fjs0j39hw2d7mwtt6t80000gn/T/ipykernel_65767/2971115876.py:12: SyntaxWarning: \"\\S\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\S\"? A raw string is also an option.\n",
      "  text = re.sub('@\\S+', '  ', text)\n",
      "/var/folders/2l/wp6j5fjs0j39hw2d7mwtt6t80000gn/T/ipykernel_65767/2971115876.py:13: SyntaxWarning: \"\\]\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\]\"? A raw string is also an option.\n",
      "  text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', text)\n",
      "/var/folders/2l/wp6j5fjs0j39hw2d7mwtt6t80000gn/T/ipykernel_65767/2971115876.py:15: SyntaxWarning: \"\\s\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\s\"? A raw string is also an option.\n",
      "  text = re.sub('\\s+', ' ', text)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RESUME_PATH = \"../data/resume/UpdatedResumeDataSet.csv\"\n",
    "\n",
    "def clean_resume(text):\n",
    "    # Remove URLs, hashtags, mentions, and special characters\n",
    "    text = re.sub('http\\S+\\s*', ' ', text)\n",
    "    text = re.sub('RT|cc', ' ', text)\n",
    "    text = re.sub('#\\S+', '', text)\n",
    "    text = re.sub('@\\S+', '  ', text)\n",
    "    text = re.sub('[%s]' % re.escape(\"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\"), ' ', text)\n",
    "    text = re.sub(r'[^\\x00-\\x7f]', r' ', text) \n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Load and Clean\n",
    "df = pd.read_csv(RESUME_PATH)\n",
    "df['Resume_text'] = df['Resume'].apply(clean_resume) # Kaggle column is usually named 'Resume'\n",
    "\n",
    "# 1. Split off Pre-Evaluation (10% - Our baseline)\n",
    "df_main, df_pre_eval = train_test_split(df, test_size=0.10, random_state=42, stratify=df['Category'])\n",
    "\n",
    "# 2. Split remainder into Training (70%) and Test (20%)\n",
    "# 0.22 of 0.9 is roughly 20% of the total\n",
    "df_train, df_test = train_test_split(df_main, test_size=0.22, random_state=42, stratify=df_main['Category'])\n",
    "\n",
    "print(f\"üìä Dataset Split Complete:\")\n",
    "print(f\"   - Training Set: {len(df_train)} (To teach Gemma)\")\n",
    "print(f\"   - Test Set: {len(df_test)} (The Final Exam)\")\n",
    "print(f\"   - Pre-Eval Set: {len(df_pre_eval)} (The Baseline)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845002a-3f81-4c1a-9694-3169eafb2795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "627778a6-7b44-457b-90f0-7e4812a49b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Benchmarking 97 resumes against gemma3:4b...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97/97 [04:10<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä BASELINE RESULTS:\n",
      "   - Categorization Accuracy: 70.10%\n",
      "   - Metrics saved to 'baseline_results.json'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ollama\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "def run_baseline_on_kaggle_subset(subset_df, model_name=\"gemma3:4b\"):\n",
    "    baseline_logs = []\n",
    "    correct_hits = 0\n",
    "    \n",
    "    print(f\"üöÄ Benchmarking {len(subset_df)} resumes against {model_name}...\")\n",
    "    \n",
    "    for idx, row in tqdm(subset_df.iterrows(), total=len(subset_df)):\n",
    "        category = row['Category']\n",
    "        resume_text = row['Resume_text'][:2000] # Limit for speed\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        TASK: Identify the professional category and evaluate the candidate.\n",
    "        RESUME: {resume_text}\n",
    "        \n",
    "        INSTRUCTIONS:\n",
    "        1. Identify the Job Category.\n",
    "        2. Give a fit score (0-10).\n",
    "        3. Provide a 1-sentence rationale.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = ollama.generate(model=model_name, prompt=prompt)['response']\n",
    "        \n",
    "        # Simple accuracy check: Does the Category appear in the AI response?\n",
    "        is_correct = 1 if category.lower() in response.lower() else 0\n",
    "        correct_hits += is_correct\n",
    "        \n",
    "        baseline_logs.append({\n",
    "            \"true_category\": category,\n",
    "            \"ai_response\": response,\n",
    "            \"was_correct\": is_correct\n",
    "        })\n",
    "        \n",
    "    accuracy = (correct_hits / len(subset_df)) * 100\n",
    "    return baseline_logs, accuracy\n",
    "\n",
    "# Execute Baseline\n",
    "baseline_data, pre_accuracy = run_baseline_on_kaggle_subset(df_pre_eval)\n",
    "\n",
    "print(f\"\\nüìä BASELINE RESULTS:\")\n",
    "print(f\"   - Categorization Accuracy: {pre_accuracy:.2f}%\")\n",
    "print(f\"   - Metrics saved to 'baseline_results.json'\")\n",
    "\n",
    "# Save for Post-Training comparison\n",
    "with open('baseline_results.json', 'w') as f:\n",
    "    json.dump(baseline_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df89d4db-277f-472b-83d3-47a5dca22e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlx-lm in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (0.30.5)\n",
      "Requirement already satisfied: mlx>=0.30.3 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from mlx-lm) (0.30.4)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from mlx-lm) (2.3.5)\n",
      "Requirement already satisfied: transformers==5.0.0rc3 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from mlx-lm) (5.0.0rc3)\n",
      "Requirement already satisfied: sentencepiece in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from mlx-lm) (0.2.1)\n",
      "Requirement already satisfied: protobuf in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from mlx-lm) (6.33.4)\n",
      "Requirement already satisfied: pyyaml in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from mlx-lm) (6.0.3)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from mlx-lm) (3.1.6)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from transformers==5.0.0rc3->mlx-lm) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from transformers==5.0.0rc3->mlx-lm) (1.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from transformers==5.0.0rc3->mlx-lm) (26.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from transformers==5.0.0rc3->mlx-lm) (2026.1.15)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from transformers==5.0.0rc3->mlx-lm) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from transformers==5.0.0rc3->mlx-lm) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from transformers==5.0.0rc3->mlx-lm) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from transformers==5.0.0rc3->mlx-lm) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from transformers==5.0.0rc3->mlx-lm) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers==5.0.0rc3->mlx-lm) (2026.1.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers==5.0.0rc3->mlx-lm) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers==5.0.0rc3->mlx-lm) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers==5.0.0rc3->mlx-lm) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers==5.0.0rc3->mlx-lm) (4.15.0)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers==5.0.0rc3->mlx-lm) (4.12.1)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/opt/certifi/lib/python3.14/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers==5.0.0rc3->mlx-lm) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers==5.0.0rc3->mlx-lm) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers==5.0.0rc3->mlx-lm) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers==5.0.0rc3->mlx-lm) (0.16.0)\n",
      "Requirement already satisfied: mlx-metal==0.30.4 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from mlx>=0.30.3->mlx-lm) (0.30.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from jinja2->mlx-lm) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from requests->transformers==5.0.0rc3->mlx-lm) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from requests->transformers==5.0.0rc3->mlx-lm) (2.6.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages (from typer-slim->transformers==5.0.0rc3->mlx-lm) (8.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U mlx-lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c84faa6c-3aba-4e5c-b4fa-76d0d195591d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data files generated in /mlx_data folder!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Create a 'data' folder for MLX\n",
    "os.makedirs(\"../data/mlx_data\", exist_ok=True)\n",
    "\n",
    "def format_for_mlx(df, output_path):\n",
    "    with open(output_path, \"w\") as f:\n",
    "        for _, row in df.iterrows():\n",
    "            # Gemma 3 Chat Template formatting\n",
    "            prompt = f\"Identify the category and evaluate this resume: {row['Resume_text'][:1000]}\"\n",
    "            completion = f\"Category: {row['Category']}. Rationale: Strong matches found for professional standards in {row['Category']}.\"\n",
    "            \n",
    "            # MLX expects a single \"text\" key per line\n",
    "            full_text = f\"<start_of_turn>user\\n{prompt}<end_of_turn>\\n<start_of_turn>model\\n{completion}<end_of_turn>\"\n",
    "            f.write(json.dumps({\"text\": full_text}) + \"\\n\")\n",
    "\n",
    "# Using the splits you made earlier\n",
    "format_for_mlx(df_train, \"../data/mlx_data/train.jsonl\")\n",
    "format_for_mlx(df_test, \"../data/mlx_data/valid.jsonl\")\n",
    "\n",
    "print(\"‚úÖ Data files generated in /mlx_data folder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22373a1a-e459-44b2-8cf5-450eabcfdbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking data directory: /Users/I060587/Documents/GitHub/intelligent-recruiter/data/mlx_data\n",
      "Files found: ['train.jsonl', 'valid.jsonl']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Checking data directory:\", os.path.abspath(\"../data/mlx_data\"))\n",
    "print(\"Files found:\", os.listdir(\"../data/mlx_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57db5d67-6dcf-49b9-b90e-887d0b3c9026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no such file or directory: ../venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "# Force install into your specific virtual environment\n",
    "!../venv/bin/python -m pip install -U mlx-lm mlx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf599323-ca74-4852-ba62-0cc0280f07a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f467f718949466883f44b5bb093cf45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311b46df1e104fcd99acc1c597b68f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Category      | Gemma 3 Prediction\n",
      "--------------------------------------------------\n",
      "SAP Developer        | Category: SAP Developer\n",
      "Hadoop               | Category: Hadoop\n",
      "Blockchain           | Category: Blockchain\n",
      "Health and fitness   | Category: Health and fitness\n",
      "Testing              | Category: Testing\n"
     ]
    }
   ],
   "source": [
    "from mlx_lm import load, generate\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load the model + your new adapters\n",
    "model, tokenizer = load(\n",
    "    \"google/gemma-3-4b-it\", \n",
    "    adapter_path=\"../gemma_recruiter_adapters_v2\"\n",
    ")\n",
    "\n",
    "# 2. Pick a few samples from your test set (unseen data)\n",
    "test_samples = df_test.sample(5)\n",
    "\n",
    "print(f\"{'Actual Category':<20} | {'Gemma 3 Prediction'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for _, row in test_samples.iterrows():\n",
    "    # Format the prompt exactly like we did in training\n",
    "    prompt = f\"<start_of_turn>user\\nIdentify the category and evaluate this resume: {row['Resume_text'][:1000]}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "    \n",
    "    # Generate the response\n",
    "    response = generate(model, tokenizer, prompt=prompt, max_tokens=50)\n",
    "    \n",
    "    print(f\"{row['Category']:<20} | {response.strip()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dc3dd1c-9f6f-47fa-a155-789ae8454f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully created ../data/mlx_data/test.jsonl with 191 samples.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Define the path where the test file should go\n",
    "test_path = \"../data/mlx_data/test.jsonl\"\n",
    "\n",
    "with open(test_path, \"w\") as f:\n",
    "    for _, row in df_test.iterrows():\n",
    "        # Matching the exact prompt format used in training\n",
    "        entry = {\n",
    "            \"input\": f\"Identify the category and evaluate this resume: {row['Resume_text'][:1000]}\",\n",
    "            \"output\": f\"Category: {row['Category']}. Rationale: Strong matches found for professional standards in {row['Category']}.\"\n",
    "        }\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "print(f\"‚úÖ Successfully created {test_path} with {len(df_test)} samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26968f5d-2e8b-4d2a-ba8f-31470e62f92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 66.49%\n",
      "\n",
      "Detailed Report:\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                 Advocate       0.00      0.00      0.00         4\n",
      "        Android Developer       0.00      0.00      0.00         0\n",
      "                     Arts       1.00      0.29      0.44         7\n",
      "               Automation       0.00      0.00      0.00         0\n",
      "       Automation Testing       1.00      0.40      0.57         5\n",
      "               Blockchain       1.00      1.00      1.00         8\n",
      "         Business Analyst       1.00      1.00      1.00         5\n",
      "           Civil Engineer       1.00      1.00      1.00         5\n",
      "             Data Science       1.00      1.00      1.00         8\n",
      "                 Database       1.00      1.00      1.00         7\n",
      "          Design Engineer       0.00      0.00      0.00         0\n",
      "          DevOps Engineer       1.00      0.91      0.95        11\n",
      "         DotNet Developer       1.00      1.00      1.00         5\n",
      "                      ETL       0.00      0.00      0.00         0\n",
      "            ETL Developer       1.00      1.00      1.00         8\n",
      "      Electrical Engineer       0.00      0.00      0.00         0\n",
      "   Electrical Engineering       0.00      0.00      0.00         6\n",
      "              Electronics       0.00      0.00      0.00         0\n",
      "     Electronics Engineer       0.00      0.00      0.00         0\n",
      "                  Fitness       0.00      0.00      0.00         0\n",
      "                       HR       1.00      0.78      0.88         9\n",
      "                   Hadoop       1.00      0.75      0.86         8\n",
      "                   Health       0.00      0.00      0.00         0\n",
      "       Health and fitness       0.00      0.00      0.00         6\n",
      "                       IT       0.00      0.00      0.00         0\n",
      "          Interior Design       0.00      0.00      0.00         0\n",
      "           Java Developer       0.85      1.00      0.92        17\n",
      "                    Legal       0.00      0.00      0.00         0\n",
      "                Marketing       0.00      0.00      0.00         0\n",
      "      Mechanical Engineer       1.00      0.62      0.77         8\n",
      "         Network Security       0.00      0.00      0.00         0\n",
      "Network Security Engineer       0.00      0.00      0.00         5\n",
      "               Networking       0.00      0.00      0.00         0\n",
      "               Operations       0.00      0.00      0.00         0\n",
      "       Operations Manager       1.00      0.38      0.55         8\n",
      "                      PMO       1.00      0.67      0.80         6\n",
      "            Power Systems       0.00      0.00      0.00         0\n",
      "          Project Manager       0.00      0.00      0.00         0\n",
      "         Python Developer       1.00      0.89      0.94         9\n",
      "          Quality Control       0.00      0.00      0.00         0\n",
      "                      SAP       0.00      0.00      0.00         0\n",
      "            SAP Developer       0.00      0.00      0.00         5\n",
      "                    Sales       1.00      1.00      1.00         8\n",
      "        Software Engineer       0.00      0.00      0.00         0\n",
      "              Solar Power       0.00      0.00      0.00         0\n",
      "                 Taxation       0.00      0.00      0.00         0\n",
      "                  Testing       1.00      0.21      0.35        14\n",
      "            Web Designing       1.00      0.67      0.80         9\n",
      "Web and Graphics Designer       0.00      0.00      0.00         0\n",
      "\n",
      "                 accuracy                           0.66       191\n",
      "                macro avg       0.41      0.32      0.34       191\n",
      "             weighted avg       0.85      0.66      0.72       191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Load the test data\n",
    "with open(\"../data/mlx_data/test.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        # Extract the ground truth category from the 'output' field\n",
    "        # This assumes your JSONL output was \"Category: X\"\n",
    "        actual = data['output'].split(\"Category: \")[1].split(\".\")[0].strip()\n",
    "        y_true.append(actual)\n",
    "        \n",
    "        # Get the prediction from the model\n",
    "        prompt = f\"<start_of_turn>user\\nIdentify the category and evaluate this resume: {data['input'][:1000]}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "        response = generate(model, tokenizer, prompt=prompt, max_tokens=20)\n",
    "        \n",
    "        try:\n",
    "            prediction = response.strip().split(\"Category: \")[1].split(\".\")[0].strip()\n",
    "        except:\n",
    "            prediction = \"Error\"\n",
    "        y_pred.append(prediction)\n",
    "\n",
    "# Calculate final stats\n",
    "print(f\"Final Accuracy: {accuracy_score(y_true, y_pred) * 100:.2f}%\")\n",
    "print(\"\\nDetailed Report:\\n\", classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05c0375a-c902-48f0-b4e2-18f0278376fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 92.15%\n",
      "\n",
      "Detailed Report:\n",
      "                            precision    recall  f1-score   support\n",
      "\n",
      "                 Advocate       1.00      1.00      1.00         4\n",
      "                     Arts       1.00      0.29      0.44         7\n",
      "    Arts Commerce Science       0.00      0.00      0.00         0\n",
      "             Arts Manager       0.00      0.00      0.00         0\n",
      "       Automation Testing       1.00      1.00      1.00         5\n",
      "               Blockchain       1.00      1.00      1.00         8\n",
      "         Business Analyst       1.00      1.00      1.00         5\n",
      "           Civil Engineer       1.00      1.00      1.00         5\n",
      "             Data Science       1.00      1.00      1.00         8\n",
      "                 Database       1.00      0.71      0.83         7\n",
      "          DevOps Engineer       0.85      1.00      0.92        11\n",
      "         DotNet Developer       0.83      1.00      0.91         5\n",
      "            ETL Developer       0.80      1.00      0.89         8\n",
      "   Electrical Engineering       1.00      1.00      1.00         6\n",
      "                       HR       0.78      0.78      0.78         9\n",
      "                   Hadoop       1.00      0.75      0.86         8\n",
      "       Health and fitness       0.67      1.00      0.80         6\n",
      "           Java Developer       1.00      0.94      0.97        17\n",
      "      Mechanical Engineer       1.00      1.00      1.00         8\n",
      "           MySQL Database       0.00      0.00      0.00         0\n",
      "Network Security Engineer       1.00      0.60      0.75         5\n",
      "       Operations Manager       1.00      1.00      1.00         8\n",
      "                      PMO       1.00      1.00      1.00         6\n",
      "         Python Developer       1.00      0.89      0.94         9\n",
      "            SAP Developer       1.00      1.00      1.00         5\n",
      "                    Sales       1.00      1.00      1.00         8\n",
      "                  Testing       0.93      1.00      0.97        14\n",
      "            Web Designing       1.00      1.00      1.00         9\n",
      "\n",
      "                 accuracy                           0.92       191\n",
      "                macro avg       0.85      0.82      0.82       191\n",
      "             weighted avg       0.95      0.92      0.92       191\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/opt/homebrew/Cellar/jupyterlab/4.5.3/libexec/lib/python3.14/site-packages/sklearn/metrics/_classification.py:1833: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "# Load the test data\n",
    "with open(\"../data/mlx_data/test.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        # Extract the ground truth category from the 'output' field\n",
    "        # This assumes your JSONL output was \"Category: X\"\n",
    "        actual = data['output'].split(\"Category: \")[1].split(\".\")[0].strip()\n",
    "        y_true.append(actual)\n",
    "        \n",
    "        # Get the prediction from the model\n",
    "        prompt = f\"<start_of_turn>user\\nIdentify the category and evaluate this resume: {data['input'][:1000]}<end_of_turn>\\n<start_of_turn>model\\n\"\n",
    "        response = generate(model, tokenizer, prompt=prompt, max_tokens=20)\n",
    "        \n",
    "        try:\n",
    "            prediction = response.strip().split(\"Category: \")[1].split(\".\")[0].strip()\n",
    "        except:\n",
    "            prediction = \"Error\"\n",
    "        y_pred.append(prediction)\n",
    "\n",
    "# Calculate final stats\n",
    "print(f\"Final Accuracy: {accuracy_score(y_true, y_pred) * 100:.2f}%\")\n",
    "print(\"\\nDetailed Report:\\n\", classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b6545b4-2595-48b7-b680-13d4f7defc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Verified & Created: ../data/mlx_data/train.jsonl\n",
      "‚úÖ Verified & Created: ../data/mlx_data/valid.jsonl\n",
      "\n",
      "Sanity Check - Keys found: ['prompt', 'completion']\n",
      "üöÄ KEYS ARE PERFECT.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# 1. Define paths\n",
    "data_dir = \"../data/mlx_data\"\n",
    "train_file = os.path.join(data_dir, \"train.jsonl\")\n",
    "valid_file = os.path.join(data_dir, \"valid.jsonl\")\n",
    "\n",
    "def strict_mlx_format(df, output_path):\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for _, row in df.iterrows():\n",
    "            # IMPORTANT: MLX needs a leading space for some completions to tokenize correctly\n",
    "            # We also ensure NO extra keys are in the dictionary\n",
    "            entry = {\n",
    "                \"prompt\": f\"Identify the category and evaluate this resume: {str(row['Resume_text'])[:1000]}\",\n",
    "                \"completion\": f\" Category: {row['Category']}. Rationale: Strong matches found for professional standards in {row['Category']}.\"\n",
    "            }\n",
    "            f.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"‚úÖ Verified & Created: {output_path}\")\n",
    "\n",
    "# 2. Re-create the files\n",
    "strict_mlx_format(df_train, train_file)\n",
    "strict_mlx_format(df_test, valid_file)\n",
    "\n",
    "# 3. Final Sanity Check: Read the first line of the new file\n",
    "with open(train_file, 'r') as f:\n",
    "    first_line = json.loads(f.readline())\n",
    "    print(f\"\\nSanity Check - Keys found: {list(first_line.keys())}\")\n",
    "    if set(first_line.keys()) == {\"prompt\", \"completion\"}:\n",
    "        print(\"üöÄ KEYS ARE PERFECT.\")\n",
    "    else:\n",
    "        print(\"‚ùå KEYS ARE WRONG. Should only be ['prompt', 'completion']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d584f44-08b2-4c30-a74d-04798727d0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created clean train.jsonl at /Users/I060587/Documents/GitHub/intelligent-recruiter/pipelines/mlx_data_clean/train.jsonl\n",
      "‚úÖ Created clean valid.jsonl at /Users/I060587/Documents/GitHub/intelligent-recruiter/pipelines/mlx_data_clean/valid.jsonl\n",
      "\n",
      "üöÄ COPY THIS PATH FOR YOUR COMMAND: /Users/I060587/Documents/GitHub/intelligent-recruiter/pipelines/mlx_data_clean\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Use ABSOLUTE paths to avoid path resolution bugs\n",
    "data_dir = Path(\"./mlx_data_clean\").resolve()\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "def write_clean_jsonl(df, name):\n",
    "    path = data_dir / f\"{name}.jsonl\"\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for i, (_, row) in enumerate(df.iterrows()):\n",
    "            entry = {\n",
    "                \"prompt\": f\"Identify category: {str(row['Resume_text'])[:500]}\",\n",
    "                \"completion\": f\" Category: {row['Category']}\"\n",
    "            }\n",
    "            # Remove any possible newlines within the text itself\n",
    "            json_record = json.dumps(entry, ensure_ascii=False)\n",
    "            f.write(json_record + (\"\\n\" if i < len(df) - 1 else \"\")) # No trailing newline at end of file\n",
    "    print(f\"‚úÖ Created clean {name}.jsonl at {path}\")\n",
    "\n",
    "write_clean_jsonl(df_train, \"train\")\n",
    "write_clean_jsonl(df_test, \"valid\")\n",
    "\n",
    "print(f\"\\nüöÄ COPY THIS PATH FOR YOUR COMMAND: {data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6585c33e-42ff-415c-b810-26002ca1c1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
